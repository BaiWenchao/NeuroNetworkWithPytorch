{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义拟合网络：将输入的变量映射到最后的值：\n",
    "class FitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "                nn.Linear(100, 300),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(300, 500),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(500, 300),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(300, 1)\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "# 将定义的模型实例化：\n",
    "fitNet = FitModel()\n",
    "# 为实例化后的模型定义优化器\n",
    "fitOpt = optim.SGD(fitNet.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成网络：生成100个输入值：\n",
    "\n",
    "# 由于输入值只能为1或-1，所以选取tanh函数，通过对x放大，可以将实数域的值\n",
    "# 映射到近似1或-1两个值（可以绘制tanh(100x)的图形帮助理解）\n",
    "# 于是定义如下激活函数：\n",
    "class MyTanh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyTanh, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(100*x)\n",
    "        return x \n",
    "\n",
    "# 接下来定义生成网络：\n",
    "class GenModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 网络1：得出输入        \n",
    "        self.net = nn.Sequential(\n",
    "                nn.Linear(100, 300),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(300, 500),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(500, 600),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(600, 500),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(500, 300),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(300, 100),\n",
    "                MyTanh()\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "genNet = GenModel()\n",
    "genOpt = optim.SGD(genNet.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出获取函数\n",
    "def getOutput(inList):\n",
    "    return random.randint(0, 10)\n",
    "\n",
    "# 输入输出获取函数\n",
    "def generateInput(size):\n",
    "    inputList = []\n",
    "    outputList=[]\n",
    "    i=0\n",
    "    while i<size: \n",
    "        inList = []\n",
    "        for j in range(100):\n",
    "            item = random.randint(0, 1)\n",
    "            if item == 0:\n",
    "                item = -1\n",
    "            inList.append(item)\n",
    "        outList=getOutput(inList)\n",
    "        i=i+1\n",
    "        inputList.append(inList)\n",
    "        outputList.append(outList)\n",
    "        \n",
    "    return inputList,outputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取输入数据与输出数据：\n",
    "inputList,outputList = generateInput(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对输入数据与输出数据tensor包装，以便输入神经网络进行训练：\n",
    "inputList = torch.tensor(inputList)\n",
    "outputList = torch.tensor(outputList).unsqueeze(1)\n",
    "\n",
    "# 进行训练集与测试集划分：\n",
    "n_samples = inputList.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "input_train = inputList[train_indices]     # 训练集：输入数据\n",
    "output_train = outputList[train_indices]   # 训练集：输出数据\n",
    "\n",
    "input_val = inputList[val_indices]         # 测试集：输入数据\n",
    "output_val = outputList[val_indices]       # 测试集：输出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义拟合网络的训练函数：\n",
    "def fitTrain(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train)\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "\n",
    "        t_p_val = model(t_u_val)\n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 50 == 0:\n",
    "            print('Epoch {}, Training loss {}, Validation loss {}'.format(\n",
    "                epoch, float(loss_train), float(loss_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 36.51694869995117, Validation loss 39.02036666870117\n",
      "Epoch 50, Training loss 5.6283488273620605, Validation loss 10.69279670715332\n",
      "Epoch 100, Training loss 4.953967094421387, Validation loss 18.365276336669922\n",
      "Epoch 150, Training loss 1.0587949752807617, Validation loss 15.169242858886719\n",
      "Epoch 200, Training loss 0.42391857504844666, Validation loss 14.633149147033691\n"
     ]
    }
   ],
   "source": [
    "# 进行拟合函数的训练：\n",
    "fitTrain(\n",
    "    n_epochs = 200, \n",
    "    optimizer = fitOpt,\n",
    "    model = fitNet,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = input_train.float(),\n",
    "    t_u_val = input_val.float(), \n",
    "    t_c_train = output_train.float(),\n",
    "    t_c_val = output_val.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拟合网络训练结束后，冻结其全部参数，以免在生成网络的训练过程中被修改：\n",
    "fitNet.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成网络的训练：\n",
    "def genTrain(n_epochs, optimizer, model):\n",
    "    val = torch.ones(100)\n",
    "    out = 0\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        out = model(val)\n",
    "        \n",
    "        # 我们希望fitNet(out)的值越大越好\n",
    "#         loss = torch.exp(1/fitNet(out))\n",
    "        loss = -fitNet(out)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 500 == 0:\n",
    "            print('Epoch {}, loss {}'.format(\n",
    "                epoch, float(loss)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss -5.791012287139893\n",
      "Epoch 500, loss -7.239447116851807\n",
      "Epoch 1000, loss -7.4095683097839355\n",
      "Epoch 1500, loss -7.4095683097839355\n",
      "Epoch 2000, loss -7.4095683097839355\n",
      "Epoch 2500, loss -7.4095683097839355\n"
     ]
    }
   ],
   "source": [
    "# 进行生成网络的训练：\n",
    "out = genTrain(2500, genOpt, genNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,\n",
       "         1.,  1.,  1., -1., -1., -1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,\n",
       "         1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "        -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
       "         1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,\n",
       "         1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "        -1., -1.], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
