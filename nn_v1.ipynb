{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数\n",
    "\n",
    "#折射率\n",
    "def n(omega):\n",
    "    if(omega>1e14):\n",
    "        t=100\n",
    "        a1=4.582\n",
    "        a2=0.09921\n",
    "        a3=0.2109\n",
    "        a4=-0.02194\n",
    "        b1=0.00000022971\n",
    "        b2=0.000000052716\n",
    "        b3=-0.000000049143\n",
    "        c=88506.25\n",
    "        t1=t+273.15\n",
    "        \n",
    "        w=(2*np.pi*3e8/omega)*1e6\n",
    "        c1=w*w-(a3+b3*(t1*t1-c))*(a3+b3*(t1*t1-c))\n",
    "        c2=a1+b1*(t1*t1-c)+(a2+b2*(t1*t1-c))/c1+a4*w*w\n",
    "        y=np.sqrt(abs(c2))\n",
    "    else:\n",
    "        d1=19.9\n",
    "        d2=44\n",
    "        d3=4.533e12*2*np.pi\n",
    "        d4=0.426e12*2*np.pi\n",
    "        d5=2.9176e13\n",
    "        \n",
    "        e=d1+(d2-d1)*d5**2/(d3**2+1.0j*omega*d4-omega**2)\n",
    "        y=np.real(np.sqrt(abs(e)))\n",
    "\n",
    "    return y\n",
    "\n",
    "def kk(f):\n",
    "    z=f*n(f)/3e8\n",
    "    return z\n",
    "\n",
    "def funct(val):\n",
    "    G=np.zeros([2,300])\n",
    "    d=np.zeros([2,100])\n",
    "        \n",
    "    d[1,:] = val\n",
    "        \n",
    "    for j in range(100):\n",
    "        d[0,j] = j*3e-6\n",
    "        \n",
    "    for k in range(300):\n",
    "        f_thz=0.1e12+k*0.15e12\n",
    "        f_nir=3e8/800e-9\n",
    "        G[0,k]=-kk(2*np.pi*f_nir)+kk(2*np.pi*(f_nir-f_thz))+kk(2*np.pi*f_thz)\n",
    "        \n",
    "    for ii in range(300):\n",
    "        for jj in range(100):\n",
    "            if jj == 99:\n",
    "                break\n",
    "            G[1,ii]=G[1,ii]+d[1,jj]*np.exp(1.0j*G[0,ii]*d[0,jj+1])-np.exp(1.0j*G[0,ii]*d[0,jj])/(1.0j*G[0,ii])\n",
    "        \n",
    "    peak = np.max(np.abs(G[1,:]))\n",
    "    G_au = np.abs(G[1,:])/peak\n",
    "        \n",
    "    max_index = G_au.tolist().index(1)\n",
    "        \n",
    "    lo = max_index \n",
    "    # 前向搜索\n",
    "    while G_au[lo] > 0.5 and lo > 0:\n",
    "        lo -= 1\n",
    "        if G_au[lo] <= 0.5:\n",
    "            break \n",
    "\n",
    "    hi = max_index\n",
    "    # 后向搜索\n",
    "    while G_au[hi] > 0.5 and hi < 299:\n",
    "        hi += 1\n",
    "        if G_au[hi] <= 0.5:\n",
    "            break\n",
    "\n",
    "    if(hi==299 and G_au[hi]>0.5)or(lo==0 and G_au[lo]>0.5):\n",
    "        bw=0.01\n",
    "    else:\n",
    "        bw = hi - lo\n",
    "    return bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义拟合网络：将输入的100个变量映射到最后的值：\n",
    "class FitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_linear = nn.Linear(100, 300)\n",
    "        self.hidden_activation = nn.ReLU()\n",
    "        self.output_linear = nn.Linear(300, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        hidden_t = self.hidden_linear(input)\n",
    "        activated_t = self.hidden_activation(hidden_t)\n",
    "        output_t = self.output_linear(activated_t)\n",
    "        \n",
    "        return output_t\n",
    "\n",
    "# 将定义的模型实例化：\n",
    "fitNet = FitModel()\n",
    "\n",
    "# 为实例化后的模型定义优化器\n",
    "fitOpt = optim.SGD(fitNet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成网络：生成100个输入值：\n",
    "\n",
    "# 由于输入值只能为1或-1，所以选取tanh函数，通过对x放大，可以将实数域的值\n",
    "# 映射到近似1或-1两个值（可以绘制tanh(100x)的图形帮助理解）\n",
    "# 于是定义如下激活函数：\n",
    "class MyTanh(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyTanh, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(100 * x)\n",
    "        return x \n",
    "\n",
    "# 接下来定义生成网络：\n",
    "class GenModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 网络1：得出输入\n",
    "        self.hidden_linear = nn.Linear(100, 300)\n",
    "        self.hidden_activation = nn.Tanh()\n",
    "        self.output_linear = nn.Linear(300, 100)\n",
    "        self.output_activation = MyTanh()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        hidden_t = self.hidden_linear(input)\n",
    "        activated_t = self.hidden_activation(hidden_t)\n",
    "        output_t = self.output_linear(activated_t)\n",
    "        opa = self.output_activation(output_t)\n",
    "        \n",
    "        return opa\n",
    "\n",
    "genNet = GenModel()\n",
    "genOpt = optim.SGD(genNet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练拟合网络：\n",
    "\n",
    "# 1. 构造训练集与测试集：\n",
    "# 输入获取函数\n",
    "def generateInput(size):\n",
    "    inputList = []\n",
    "    \n",
    "    for i in range(size): \n",
    "        inList = []\n",
    "        for j in range(100):\n",
    "            item = random.randint(0, 1)\n",
    "            if item == 0:\n",
    "                item = -1\n",
    "            inList.append(item)\n",
    "        inputList.append(inList)\n",
    "        \n",
    "    return inputList\n",
    "\n",
    "# 输出获取函数\n",
    "def getOutput(inputList):\n",
    "    outputList = []\n",
    "    for i in range(len(inputList)):\n",
    "        G=np.zeros([2,300])\n",
    "        d=np.zeros([2,100])\n",
    "        \n",
    "        d[1,:] = np.array(inputList)[i,:]\n",
    "        \n",
    "        for j in range(100):\n",
    "            d[0,j] = j*3e-6\n",
    "        \n",
    "        for k in range(300):\n",
    "            f_thz=0.1e12+k*0.15e12\n",
    "            f_nir=3e8/800e-9\n",
    "            G[0,k]=-kk(2*np.pi*f_nir)+kk(2*np.pi*(f_nir-f_thz))+kk(2*np.pi*f_thz)\n",
    "        \n",
    "        for ii in range(300):\n",
    "            for jj in range(100):\n",
    "                if jj == 99:\n",
    "                    break\n",
    "                G[1,ii]=G[1,ii]+d[1,jj]*np.exp(1.0j*G[0,ii]*d[0,jj+1])-np.exp(1.0j*G[0,ii]*d[0,jj])/(1.0j*G[0,ii])\n",
    "        \n",
    "        peak = np.max(np.abs(G[1,:]))\n",
    "        G_au = np.abs(G[1,:])/peak\n",
    "        \n",
    "        max_index = G_au.tolist().index(1)\n",
    "        \n",
    "        lo = max_index \n",
    "        # 前向搜索\n",
    "        while G_au[lo] > 0.5 and lo > 0:\n",
    "            lo -= 1\n",
    "            if G_au[lo] <= 0.5:\n",
    "                break \n",
    "        \n",
    "        hi = max_index\n",
    "        # 后向搜索\n",
    "        while G_au[hi] > 0.5 and hi < 299:\n",
    "            hi += 1\n",
    "            if G_au[hi] <= 0.5:\n",
    "                break\n",
    "        \n",
    "        if(hi==299 and G_au[hi]>0.5)or(lo==0 and G_au[lo]>0.5):\n",
    "            bw=-1\n",
    "        else:\n",
    "            bw = hi - lo\n",
    "        outputList.append(bw)\n",
    "    \n",
    "    return outputList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20241\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:40: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    }
   ],
   "source": [
    "# 获取输入数据与输出数据：\n",
    "inputList = generateInput(50)\n",
    "outputList = getOutput(inputList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对输入数据与输出数据tensor包装，以便输入神经网络进行训练：\n",
    "inputList = torch.tensor(inputList)\n",
    "outputList = torch.tensor(outputList).unsqueeze(1)\n",
    "\n",
    "# 进行训练集与测试集划分：\n",
    "n_samples = inputList.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "input_train = inputList[train_indices]     # 训练集：输入数据\n",
    "output_train = outputList[train_indices]   # 训练集：输出数据\n",
    "\n",
    "input_val = inputList[val_indices]         # 测试集：输入数据\n",
    "output_val = outputList[val_indices]       # 测试集：输出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义拟合网络的训练函数：\n",
    "def fitTrain(n_epochs, optimizer, model, loss_fn, t_u_train, t_u_val, t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train)\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "\n",
    "        t_p_val = model(t_u_val)\n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 50 == 0:\n",
    "            print('Epoch {}, Training loss {}, Validation loss {}'.format(\n",
    "                epoch, float(loss_train), float(loss_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 36.82501220703125, Validation loss 7.651153564453125\n",
      "Epoch 50, Training loss 30.65987777709961, Validation loss 4.707790851593018\n",
      "Epoch 100, Training loss 26.146820068359375, Validation loss 2.8960328102111816\n",
      "Epoch 150, Training loss 22.84134292602539, Validation loss 1.8686186075210571\n",
      "Epoch 200, Training loss 20.360076904296875, Validation loss 1.3463401794433594\n"
     ]
    }
   ],
   "source": [
    "# 进行拟合函数的训练：\n",
    "fitTrain(\n",
    "    n_epochs = 200, \n",
    "    optimizer = fitOpt,\n",
    "    model = fitNet,\n",
    "    loss_fn = nn.MSELoss(),\n",
    "    t_u_train = input_train.float(),\n",
    "    t_u_val = input_val.float(), \n",
    "    t_c_train = output_train.float(),\n",
    "    t_c_val = output_val.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拟合网络训练结束后，冻结其全部参数，以免在生成网络的训练过程中被修改：\n",
    "fitNet.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成网络的训练：\n",
    "# 通过输出的out参数：genNet的参数确实发生了变化，但是变化很小，甚至转为1或-1时就没变化了\n",
    "def genTrain(n_epochs, optimizer, model):\n",
    "    val = torch.ones(100)\n",
    "    out = 0\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        out = model(val)\n",
    "        \n",
    "        # 我们希望fitNet(out)的值越大越好，所以取倒数作为损失函数（乘10为了结果不是特别小）\n",
    "        loss = 10/fitNet(out)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 100 == 0:\n",
    "            print('Epoch {}, loss {}, out {}'.format(\n",
    "                epoch, float(loss), out))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 4.22904109954834, out tensor([ 1.0000, -0.9996, -1.0000, -0.5706, -0.9994, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "         0.6073, -1.0000, -1.0000,  1.0000,  0.4620, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -0.9970, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  0.9999, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000, -0.9350, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  0.9998, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -1.0000,  1.0000, -0.8049,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7911,  1.0000, -0.9777,\n",
      "         1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
      "        -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000, -1.0000, -1.0000, -1.0000, -0.9918,  1.0000,  1.0000, -1.0000,\n",
      "        -1.0000, -1.0000,  1.0000,  1.0000], grad_fn=<TanhBackward>)\n",
      "Epoch 100, loss 3.9923014640808105, out tensor([ 1.0000, -0.9999, -1.0000,  0.9994, -0.9995, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "        -0.9998, -1.0000, -1.0000,  1.0000,  0.9970, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -0.9998, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  0.9999, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000, -0.9991, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  0.9999, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -1.0000,  1.0000, -0.9995,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9996,  1.0000, -0.9990,\n",
      "         1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
      "        -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000, -1.0000, -1.0000, -1.0000, -0.9993,  1.0000,  1.0000, -1.0000,\n",
      "        -1.0000, -1.0000,  1.0000,  1.0000], grad_fn=<TanhBackward>)\n",
      "Epoch 200, loss 3.9921748638153076, out tensor([ 1.0000, -0.9999, -1.0000,  0.9997, -0.9996, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "        -0.9999, -1.0000, -1.0000,  1.0000,  0.9985, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  0.9999, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000, -0.9996, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  0.9999, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -1.0000,  1.0000, -0.9998,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998,  1.0000, -0.9995,\n",
      "         1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
      "        -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000, -1.0000, -1.0000, -1.0000, -0.9997,  1.0000,  1.0000, -1.0000,\n",
      "        -1.0000, -1.0000,  1.0000,  1.0000], grad_fn=<TanhBackward>)\n",
      "Epoch 300, loss 3.992128610610962, out tensor([ 1.0000, -1.0000, -1.0000,  0.9998, -0.9997, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "        -0.9999, -1.0000, -1.0000,  1.0000,  0.9990, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000, -0.9997, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -1.0000,  1.0000, -0.9998,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9998,  1.0000, -0.9997,\n",
      "         1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
      "        -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000, -1.0000, -1.0000, -1.0000, -0.9998,  1.0000,  1.0000, -1.0000,\n",
      "        -1.0000, -1.0000,  1.0000,  1.0000], grad_fn=<TanhBackward>)\n",
      "Epoch 400, loss 3.9921042919158936, out tensor([ 1.0000, -1.0000, -1.0000,  0.9999, -0.9998, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "        -0.9999, -1.0000, -1.0000,  1.0000,  0.9993, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -0.9999, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000, -0.9998, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -1.0000,  1.0000, -0.9999,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999,  1.0000, -0.9997,\n",
      "         1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
      "        -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000, -1.0000, -1.0000, -1.0000, -0.9998,  1.0000,  1.0000, -1.0000,\n",
      "        -1.0000, -1.0000,  1.0000,  1.0000], grad_fn=<TanhBackward>)\n",
      "Epoch 500, loss 3.9920897483825684, out tensor([ 1.0000, -1.0000, -1.0000,  0.9999, -0.9998, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000,  1.0000,  0.9994, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,\n",
      "         1.0000,  1.0000,  1.0000, -0.9998, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
      "         1.0000, -1.0000,  1.0000, -0.9999,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999,  1.0000, -0.9998,\n",
      "         1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
      "        -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
      "         1.0000, -1.0000, -1.0000, -1.0000, -0.9999,  1.0000,  1.0000, -1.0000,\n",
      "        -1.0000, -1.0000,  1.0000,  1.0000], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 进行生成网络的训练：\n",
    "out = genTrain(500, genOpt, genNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000, -1.0000, -1.0000,  0.9999, -0.9998, -1.0000, -1.0000, -1.0000,\n",
       "         1.0000,  1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000,\n",
       "        -1.0000, -1.0000, -1.0000,  1.0000,  0.9994, -1.0000, -1.0000, -1.0000,\n",
       "         1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
       "         1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,\n",
       "         1.0000,  1.0000,  1.0000, -0.9998, -1.0000, -1.0000,  1.0000, -1.0000,\n",
       "         1.0000,  1.0000, -1.0000, -1.0000,  1.0000,  1.0000, -1.0000, -1.0000,\n",
       "         1.0000, -1.0000,  1.0000, -0.9999,  1.0000,  1.0000,  1.0000,  1.0000,\n",
       "        -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9999,  1.0000, -0.9998,\n",
       "         1.0000, -1.0000,  1.0000,  1.0000, -1.0000,  1.0000, -1.0000,  1.0000,\n",
       "        -1.0000, -1.0000,  1.0000, -1.0000, -1.0000, -1.0000,  1.0000, -1.0000,\n",
       "         1.0000, -1.0000, -1.0000, -1.0000, -0.9999,  1.0000,  1.0000, -1.0000,\n",
       "        -1.0000, -1.0000,  1.0000,  1.0000], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
