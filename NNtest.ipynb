{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#折射率\n",
    "def n(omega):\n",
    "    if(omega>1e14):\n",
    "        t=100\n",
    "        a1=4.582\n",
    "        a2=0.09921\n",
    "        a3=0.2109\n",
    "        a4=-0.02194\n",
    "        b1=0.00000022971\n",
    "        b2=0.000000052716\n",
    "        b3=-0.000000049143\n",
    "        c=88506.25\n",
    "        t1=t+273.15\n",
    "        \n",
    "        w=(2*np.pi*3e8/omega)*1e6\n",
    "        c1=w*w-(a3+b3*(t1*t1-c))*(a3+b3*(t1*t1-c))\n",
    "        c2=a1+b1*(t1*t1-c)+(a2+b2*(t1*t1-c))/c1+a4*w*w\n",
    "        y=np.sqrt(abs(c2))\n",
    "    else:\n",
    "        d1=19.9\n",
    "        d2=44\n",
    "        d3=4.533e12*2*np.pi\n",
    "        d4=0.426e12*2*np.pi\n",
    "        d5=2.9176e13\n",
    "        \n",
    "        e=d1+(d2-d1)*d5**2/(d3**2+1.0j*omega*d4-omega**2)\n",
    "        y=np.real(np.sqrt(abs(e)))\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kk(f):\n",
    "    z=f*n(f)/3e8\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funct(val):\n",
    "    G=np.zeros([2,300])\n",
    "    d=np.zeros([2,100])\n",
    "        \n",
    "    d[1,:] = val\n",
    "        \n",
    "    for j in range(100):\n",
    "        d[0,j] = j*3e-6\n",
    "        \n",
    "    for k in range(300):\n",
    "        f_thz=0.1e12+k*0.15e12\n",
    "        f_nir=3e8/800e-9\n",
    "        G[0,k]=-kk(2*np.pi*f_nir)+kk(2*np.pi*(f_nir-f_thz))+kk(2*np.pi*f_thz)\n",
    "        \n",
    "    for ii in range(300):\n",
    "        for jj in range(100):\n",
    "            if jj == 99:\n",
    "                break\n",
    "            G[1,ii]=G[1,ii]+d[1,jj]*np.exp(1.0j*G[0,ii]*d[0,jj+1])-np.exp(1.0j*G[0,ii]*d[0,jj])/(1.0j*G[0,ii])\n",
    "        \n",
    "    peak = np.max(np.abs(G[1,:]))\n",
    "    G_au = np.abs(G[1,:])/peak\n",
    "        \n",
    "    max_index = G_au.tolist().index(1)\n",
    "        \n",
    "    lo = max_index \n",
    "    # 前向搜索\n",
    "    while G_au[lo] > 0.5 and lo > 0:\n",
    "        lo -= 1\n",
    "        if G_au[lo] <= 0.5:\n",
    "            break \n",
    "\n",
    "    hi = max_index\n",
    "    # 后向搜索\n",
    "    while G_au[hi] > 0.5 and hi < 299:\n",
    "        hi += 1\n",
    "        if G_au[hi] <= 0.5:\n",
    "            break\n",
    "\n",
    "    if(hi==299 and G_au[hi]>0.5)or(lo==0 and G_au[lo]>0.5):\n",
    "        bw=0.01\n",
    "    else:\n",
    "        bw = hi - lo\n",
    "    return bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(val):\n",
    "    for i in range(len(val)):\n",
    "        if val[i] > 0:\n",
    "            val[i] = 1\n",
    "        else:\n",
    "            val[i] = -1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output):\n",
    "    output = map(output)\n",
    "    #val = funct(output)\n",
    "    val = sum(output)\n",
    "    loss = 100/val\n",
    "    loss = torch.tensor(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn):\n",
    "    val = torch.ones(100)\n",
    "    a = torch.ones(1)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        out = model(val).detach() # <1>\n",
    "        \n",
    "        # loss = loss_fn(out).requires_grad_()\n",
    "        loss = loss_fn(out, a).requires_grad_()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % 5 == 0:\n",
    "            print('Epoch {}, loss {}, out{}'.format(\n",
    "                epoch, float(loss), out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20241\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:431: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 1.0370107889175415, outtensor([ 0.6905,  0.5763,  0.0996,  0.6856, -0.1091,  0.4390,  0.1200,  0.3836,\n",
      "         0.1861, -0.4535, -0.4741,  0.1909, -0.2311, -0.2071, -0.0600, -0.0746,\n",
      "        -0.0453, -0.1659, -0.0792, -0.3701,  0.2886,  0.2971, -0.3857, -0.3353,\n",
      "        -0.1416, -0.0106,  0.1773, -0.2064, -0.1346, -0.1499,  0.0760,  0.0178,\n",
      "        -0.2092,  0.2804,  0.3184,  0.0308,  0.0722,  0.1011,  0.1467,  0.0185,\n",
      "        -0.1329, -0.1916, -0.2707,  0.5302, -0.1857,  0.3334, -0.2594, -0.1899,\n",
      "        -0.1032, -0.7277,  0.0797,  0.3476,  0.3279,  0.3559,  0.1719, -0.2431,\n",
      "         0.0101,  0.5859, -0.1115, -0.1187,  0.0494, -0.0873, -0.0011,  0.1081,\n",
      "         0.0179,  0.6665, -0.0607,  0.4690,  0.2567, -0.1523,  0.2430,  0.1316,\n",
      "         0.1810, -0.1867, -0.1952, -0.0208,  0.5185, -0.0325, -0.0808, -0.2208,\n",
      "        -0.3256,  0.2664, -0.1071, -0.0230, -0.0628, -0.1156,  0.3619, -0.2283,\n",
      "         0.3857,  0.0556, -0.0842,  0.0727, -0.2320, -0.8158, -0.0820, -0.0929,\n",
      "        -0.0250, -0.0168, -0.2212,  0.2667])\n",
      "Epoch 5, loss 1.0370107889175415, outtensor([ 0.6905,  0.5763,  0.0996,  0.6856, -0.1091,  0.4390,  0.1200,  0.3836,\n",
      "         0.1861, -0.4535, -0.4741,  0.1909, -0.2311, -0.2071, -0.0600, -0.0746,\n",
      "        -0.0453, -0.1659, -0.0792, -0.3701,  0.2886,  0.2971, -0.3857, -0.3353,\n",
      "        -0.1416, -0.0106,  0.1773, -0.2064, -0.1346, -0.1499,  0.0760,  0.0178,\n",
      "        -0.2092,  0.2804,  0.3184,  0.0308,  0.0722,  0.1011,  0.1467,  0.0185,\n",
      "        -0.1329, -0.1916, -0.2707,  0.5302, -0.1857,  0.3334, -0.2594, -0.1899,\n",
      "        -0.1032, -0.7277,  0.0797,  0.3476,  0.3279,  0.3559,  0.1719, -0.2431,\n",
      "         0.0101,  0.5859, -0.1115, -0.1187,  0.0494, -0.0873, -0.0011,  0.1081,\n",
      "         0.0179,  0.6665, -0.0607,  0.4690,  0.2567, -0.1523,  0.2430,  0.1316,\n",
      "         0.1810, -0.1867, -0.1952, -0.0208,  0.5185, -0.0325, -0.0808, -0.2208,\n",
      "        -0.3256,  0.2664, -0.1071, -0.0230, -0.0628, -0.1156,  0.3619, -0.2283,\n",
      "         0.3857,  0.0556, -0.0842,  0.0727, -0.2320, -0.8158, -0.0820, -0.0929,\n",
      "        -0.0250, -0.0168, -0.2212,  0.2667])\n",
      "Epoch 10, loss 1.0370107889175415, outtensor([ 0.6905,  0.5763,  0.0996,  0.6856, -0.1091,  0.4390,  0.1200,  0.3836,\n",
      "         0.1861, -0.4535, -0.4741,  0.1909, -0.2311, -0.2071, -0.0600, -0.0746,\n",
      "        -0.0453, -0.1659, -0.0792, -0.3701,  0.2886,  0.2971, -0.3857, -0.3353,\n",
      "        -0.1416, -0.0106,  0.1773, -0.2064, -0.1346, -0.1499,  0.0760,  0.0178,\n",
      "        -0.2092,  0.2804,  0.3184,  0.0308,  0.0722,  0.1011,  0.1467,  0.0185,\n",
      "        -0.1329, -0.1916, -0.2707,  0.5302, -0.1857,  0.3334, -0.2594, -0.1899,\n",
      "        -0.1032, -0.7277,  0.0797,  0.3476,  0.3279,  0.3559,  0.1719, -0.2431,\n",
      "         0.0101,  0.5859, -0.1115, -0.1187,  0.0494, -0.0873, -0.0011,  0.1081,\n",
      "         0.0179,  0.6665, -0.0607,  0.4690,  0.2567, -0.1523,  0.2430,  0.1316,\n",
      "         0.1810, -0.1867, -0.1952, -0.0208,  0.5185, -0.0325, -0.0808, -0.2208,\n",
      "        -0.3256,  0.2664, -0.1071, -0.0230, -0.0628, -0.1156,  0.3619, -0.2283,\n",
      "         0.3857,  0.0556, -0.0842,  0.0727, -0.2320, -0.8158, -0.0820, -0.0929,\n",
      "        -0.0250, -0.0168, -0.2212,  0.2667])\n",
      "Epoch 15, loss 1.0370107889175415, outtensor([ 0.6905,  0.5763,  0.0996,  0.6856, -0.1091,  0.4390,  0.1200,  0.3836,\n",
      "         0.1861, -0.4535, -0.4741,  0.1909, -0.2311, -0.2071, -0.0600, -0.0746,\n",
      "        -0.0453, -0.1659, -0.0792, -0.3701,  0.2886,  0.2971, -0.3857, -0.3353,\n",
      "        -0.1416, -0.0106,  0.1773, -0.2064, -0.1346, -0.1499,  0.0760,  0.0178,\n",
      "        -0.2092,  0.2804,  0.3184,  0.0308,  0.0722,  0.1011,  0.1467,  0.0185,\n",
      "        -0.1329, -0.1916, -0.2707,  0.5302, -0.1857,  0.3334, -0.2594, -0.1899,\n",
      "        -0.1032, -0.7277,  0.0797,  0.3476,  0.3279,  0.3559,  0.1719, -0.2431,\n",
      "         0.0101,  0.5859, -0.1115, -0.1187,  0.0494, -0.0873, -0.0011,  0.1081,\n",
      "         0.0179,  0.6665, -0.0607,  0.4690,  0.2567, -0.1523,  0.2430,  0.1316,\n",
      "         0.1810, -0.1867, -0.1952, -0.0208,  0.5185, -0.0325, -0.0808, -0.2208,\n",
      "        -0.3256,  0.2664, -0.1071, -0.0230, -0.0628, -0.1156,  0.3619, -0.2283,\n",
      "         0.3857,  0.0556, -0.0842,  0.0727, -0.2320, -0.8158, -0.0820, -0.0929,\n",
      "        -0.0250, -0.0168, -0.2212,  0.2667])\n",
      "Epoch 20, loss 1.0370107889175415, outtensor([ 0.6905,  0.5763,  0.0996,  0.6856, -0.1091,  0.4390,  0.1200,  0.3836,\n",
      "         0.1861, -0.4535, -0.4741,  0.1909, -0.2311, -0.2071, -0.0600, -0.0746,\n",
      "        -0.0453, -0.1659, -0.0792, -0.3701,  0.2886,  0.2971, -0.3857, -0.3353,\n",
      "        -0.1416, -0.0106,  0.1773, -0.2064, -0.1346, -0.1499,  0.0760,  0.0178,\n",
      "        -0.2092,  0.2804,  0.3184,  0.0308,  0.0722,  0.1011,  0.1467,  0.0185,\n",
      "        -0.1329, -0.1916, -0.2707,  0.5302, -0.1857,  0.3334, -0.2594, -0.1899,\n",
      "        -0.1032, -0.7277,  0.0797,  0.3476,  0.3279,  0.3559,  0.1719, -0.2431,\n",
      "         0.0101,  0.5859, -0.1115, -0.1187,  0.0494, -0.0873, -0.0011,  0.1081,\n",
      "         0.0179,  0.6665, -0.0607,  0.4690,  0.2567, -0.1523,  0.2430,  0.1316,\n",
      "         0.1810, -0.1867, -0.1952, -0.0208,  0.5185, -0.0325, -0.0808, -0.2208,\n",
      "        -0.3256,  0.2664, -0.1071, -0.0230, -0.0628, -0.1156,  0.3619, -0.2283,\n",
      "         0.3857,  0.0556, -0.0842,  0.0727, -0.2320, -0.8158, -0.0820, -0.0929,\n",
      "        -0.0250, -0.0168, -0.2212,  0.2667])\n",
      "Epoch 25, loss 1.0370107889175415, outtensor([ 0.6905,  0.5763,  0.0996,  0.6856, -0.1091,  0.4390,  0.1200,  0.3836,\n",
      "         0.1861, -0.4535, -0.4741,  0.1909, -0.2311, -0.2071, -0.0600, -0.0746,\n",
      "        -0.0453, -0.1659, -0.0792, -0.3701,  0.2886,  0.2971, -0.3857, -0.3353,\n",
      "        -0.1416, -0.0106,  0.1773, -0.2064, -0.1346, -0.1499,  0.0760,  0.0178,\n",
      "        -0.2092,  0.2804,  0.3184,  0.0308,  0.0722,  0.1011,  0.1467,  0.0185,\n",
      "        -0.1329, -0.1916, -0.2707,  0.5302, -0.1857,  0.3334, -0.2594, -0.1899,\n",
      "        -0.1032, -0.7277,  0.0797,  0.3476,  0.3279,  0.3559,  0.1719, -0.2431,\n",
      "         0.0101,  0.5859, -0.1115, -0.1187,  0.0494, -0.0873, -0.0011,  0.1081,\n",
      "         0.0179,  0.6665, -0.0607,  0.4690,  0.2567, -0.1523,  0.2430,  0.1316,\n",
      "         0.1810, -0.1867, -0.1952, -0.0208,  0.5185, -0.0325, -0.0808, -0.2208,\n",
      "        -0.3256,  0.2664, -0.1071, -0.0230, -0.0628, -0.1156,  0.3619, -0.2283,\n",
      "         0.3857,  0.0556, -0.0842,  0.0727, -0.2320, -0.8158, -0.0820, -0.0929,\n",
      "        -0.0250, -0.0168, -0.2212,  0.2667])\n",
      "Epoch 30, loss 1.0370107889175415, outtensor([ 0.6905,  0.5763,  0.0996,  0.6856, -0.1091,  0.4390,  0.1200,  0.3836,\n",
      "         0.1861, -0.4535, -0.4741,  0.1909, -0.2311, -0.2071, -0.0600, -0.0746,\n",
      "        -0.0453, -0.1659, -0.0792, -0.3701,  0.2886,  0.2971, -0.3857, -0.3353,\n",
      "        -0.1416, -0.0106,  0.1773, -0.2064, -0.1346, -0.1499,  0.0760,  0.0178,\n",
      "        -0.2092,  0.2804,  0.3184,  0.0308,  0.0722,  0.1011,  0.1467,  0.0185,\n",
      "        -0.1329, -0.1916, -0.2707,  0.5302, -0.1857,  0.3334, -0.2594, -0.1899,\n",
      "        -0.1032, -0.7277,  0.0797,  0.3476,  0.3279,  0.3559,  0.1719, -0.2431,\n",
      "         0.0101,  0.5859, -0.1115, -0.1187,  0.0494, -0.0873, -0.0011,  0.1081,\n",
      "         0.0179,  0.6665, -0.0607,  0.4690,  0.2567, -0.1523,  0.2430,  0.1316,\n",
      "         0.1810, -0.1867, -0.1952, -0.0208,  0.5185, -0.0325, -0.0808, -0.2208,\n",
      "        -0.3256,  0.2664, -0.1071, -0.0230, -0.0628, -0.1156,  0.3619, -0.2283,\n",
      "         0.3857,  0.0556, -0.0842,  0.0727, -0.2320, -0.8158, -0.0820, -0.0929,\n",
      "        -0.0250, -0.0168, -0.2212,  0.2667])\n",
      "Epoch 35, loss 1.0370107889175415, outtensor([ 0.6905,  0.5763,  0.0996,  0.6856, -0.1091,  0.4390,  0.1200,  0.3836,\n",
      "         0.1861, -0.4535, -0.4741,  0.1909, -0.2311, -0.2071, -0.0600, -0.0746,\n",
      "        -0.0453, -0.1659, -0.0792, -0.3701,  0.2886,  0.2971, -0.3857, -0.3353,\n",
      "        -0.1416, -0.0106,  0.1773, -0.2064, -0.1346, -0.1499,  0.0760,  0.0178,\n",
      "        -0.2092,  0.2804,  0.3184,  0.0308,  0.0722,  0.1011,  0.1467,  0.0185,\n",
      "        -0.1329, -0.1916, -0.2707,  0.5302, -0.1857,  0.3334, -0.2594, -0.1899,\n",
      "        -0.1032, -0.7277,  0.0797,  0.3476,  0.3279,  0.3559,  0.1719, -0.2431,\n",
      "         0.0101,  0.5859, -0.1115, -0.1187,  0.0494, -0.0873, -0.0011,  0.1081,\n",
      "         0.0179,  0.6665, -0.0607,  0.4690,  0.2567, -0.1523,  0.2430,  0.1316,\n",
      "         0.1810, -0.1867, -0.1952, -0.0208,  0.5185, -0.0325, -0.0808, -0.2208,\n",
      "        -0.3256,  0.2664, -0.1071, -0.0230, -0.0628, -0.1156,  0.3619, -0.2283,\n",
      "         0.3857,  0.0556, -0.0842,  0.0727, -0.2320, -0.8158, -0.0820, -0.0929,\n",
      "        -0.0250, -0.0168, -0.2212,  0.2667])\n",
      "Epoch 40, loss 1.0370107889175415, outtensor([ 0.6905,  0.5763,  0.0996,  0.6856, -0.1091,  0.4390,  0.1200,  0.3836,\n",
      "         0.1861, -0.4535, -0.4741,  0.1909, -0.2311, -0.2071, -0.0600, -0.0746,\n",
      "        -0.0453, -0.1659, -0.0792, -0.3701,  0.2886,  0.2971, -0.3857, -0.3353,\n",
      "        -0.1416, -0.0106,  0.1773, -0.2064, -0.1346, -0.1499,  0.0760,  0.0178,\n",
      "        -0.2092,  0.2804,  0.3184,  0.0308,  0.0722,  0.1011,  0.1467,  0.0185,\n",
      "        -0.1329, -0.1916, -0.2707,  0.5302, -0.1857,  0.3334, -0.2594, -0.1899,\n",
      "        -0.1032, -0.7277,  0.0797,  0.3476,  0.3279,  0.3559,  0.1719, -0.2431,\n",
      "         0.0101,  0.5859, -0.1115, -0.1187,  0.0494, -0.0873, -0.0011,  0.1081,\n",
      "         0.0179,  0.6665, -0.0607,  0.4690,  0.2567, -0.1523,  0.2430,  0.1316,\n",
      "         0.1810, -0.1867, -0.1952, -0.0208,  0.5185, -0.0325, -0.0808, -0.2208,\n",
      "        -0.3256,  0.2664, -0.1071, -0.0230, -0.0628, -0.1156,  0.3619, -0.2283,\n",
      "         0.3857,  0.0556, -0.0842,  0.0727, -0.2320, -0.8158, -0.0820, -0.0929,\n",
      "        -0.0250, -0.0168, -0.2212,  0.2667])\n",
      "Epoch 45, loss 1.0370107889175415, outtensor([ 0.6905,  0.5763,  0.0996,  0.6856, -0.1091,  0.4390,  0.1200,  0.3836,\n",
      "         0.1861, -0.4535, -0.4741,  0.1909, -0.2311, -0.2071, -0.0600, -0.0746,\n",
      "        -0.0453, -0.1659, -0.0792, -0.3701,  0.2886,  0.2971, -0.3857, -0.3353,\n",
      "        -0.1416, -0.0106,  0.1773, -0.2064, -0.1346, -0.1499,  0.0760,  0.0178,\n",
      "        -0.2092,  0.2804,  0.3184,  0.0308,  0.0722,  0.1011,  0.1467,  0.0185,\n",
      "        -0.1329, -0.1916, -0.2707,  0.5302, -0.1857,  0.3334, -0.2594, -0.1899,\n",
      "        -0.1032, -0.7277,  0.0797,  0.3476,  0.3279,  0.3559,  0.1719, -0.2431,\n",
      "         0.0101,  0.5859, -0.1115, -0.1187,  0.0494, -0.0873, -0.0011,  0.1081,\n",
      "         0.0179,  0.6665, -0.0607,  0.4690,  0.2567, -0.1523,  0.2430,  0.1316,\n",
      "         0.1810, -0.1867, -0.1952, -0.0208,  0.5185, -0.0325, -0.0808, -0.2208,\n",
      "        -0.3256,  0.2664, -0.1071, -0.0230, -0.0628, -0.1156,  0.3619, -0.2283,\n",
      "         0.3857,  0.0556, -0.0842,  0.0727, -0.2320, -0.8158, -0.0820, -0.0929,\n",
      "        -0.0250, -0.0168, -0.2212,  0.2667])\n",
      "Epoch 50, loss 1.0370107889175415, outtensor([ 0.6905,  0.5763,  0.0996,  0.6856, -0.1091,  0.4390,  0.1200,  0.3836,\n",
      "         0.1861, -0.4535, -0.4741,  0.1909, -0.2311, -0.2071, -0.0600, -0.0746,\n",
      "        -0.0453, -0.1659, -0.0792, -0.3701,  0.2886,  0.2971, -0.3857, -0.3353,\n",
      "        -0.1416, -0.0106,  0.1773, -0.2064, -0.1346, -0.1499,  0.0760,  0.0178,\n",
      "        -0.2092,  0.2804,  0.3184,  0.0308,  0.0722,  0.1011,  0.1467,  0.0185,\n",
      "        -0.1329, -0.1916, -0.2707,  0.5302, -0.1857,  0.3334, -0.2594, -0.1899,\n",
      "        -0.1032, -0.7277,  0.0797,  0.3476,  0.3279,  0.3559,  0.1719, -0.2431,\n",
      "         0.0101,  0.5859, -0.1115, -0.1187,  0.0494, -0.0873, -0.0011,  0.1081,\n",
      "         0.0179,  0.6665, -0.0607,  0.4690,  0.2567, -0.1523,  0.2430,  0.1316,\n",
      "         0.1810, -0.1867, -0.1952, -0.0208,  0.5185, -0.0325, -0.0808, -0.2208,\n",
      "        -0.3256,  0.2664, -0.1071, -0.0230, -0.0628, -0.1156,  0.3619, -0.2283,\n",
      "         0.3857,  0.0556, -0.0842,  0.0727, -0.2320, -0.8158, -0.0820, -0.0929,\n",
      "        -0.0250, -0.0168, -0.2212,  0.2667])\n"
     ]
    }
   ],
   "source": [
    "neuron_count = 300\n",
    "\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(100, neuron_count)),\n",
    "    ('hidden_activation', nn.ReLU()),\n",
    "    ('output_linear', nn.Linear(neuron_count, 100))\n",
    "]))\n",
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-4)\n",
    "training_loop(\n",
    "    n_epochs = 50, \n",
    "    optimizer = optimizer,\n",
    "    model = seq_model,\n",
    "    loss_fn = nn.MSELoss())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
